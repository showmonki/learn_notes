Train on 48000 samples, validate on 12000 samples
Epoch 1/10
48000/48000 [==============================] - 1324s 28ms/sample - loss: 2.3283 - accuracy: 0.7666 - val_loss: 3.0288 - val_accuracy: 0.7372
Epoch 2/10
48000/48000 [==============================] - 1223s 25ms/sample - loss: 1.4682 - accuracy: 0.8610 - val_loss: 1.1414 - val_accuracy: 0.8946
Epoch 3/10
48000/48000 [==============================] - 1204s 25ms/sample - loss: 1.4218 - accuracy: 0.8784 - val_loss: 1.4617 - val_accuracy: 0.8784
Epoch 4/10
48000/48000 [==============================] - 1139s 24ms/sample - loss: 1.2923 - accuracy: 0.8933 - val_loss: 1.6425 - val_accuracy: 0.8893
Epoch 5/10
48000/48000 [==============================] - 1137s 24ms/sample - loss: 1.3336 - accuracy: 0.8999 - val_loss: 1.4855 - val_accuracy: 0.8998
Epoch 6/10
48000/48000 [==============================] - 1119s 23ms/sample - loss: 1.2212 - accuracy: 0.9084 - val_loss: 2.0308 - val_accuracy: 0.8867
Epoch 7/10
48000/48000 [==============================] - 1121s 23ms/sample - loss: 1.2417 - accuracy: 0.9128 - val_loss: 1.6823 - val_accuracy: 0.9018
Epoch 8/10
48000/48000 [==============================] - 1117s 23ms/sample - loss: 1.1902 - accuracy: 0.9171 - val_loss: 1.4528 - val_accuracy: 0.9140
Epoch 9/10
48000/48000 [==============================] - 1113s 23ms/sample - loss: 1.1681 - accuracy: 0.9198 - val_loss: 1.2009 - val_accuracy: 0.9249
Epoch 10/10
48000/48000 [==============================] - 1117s 23ms/sample - loss: 1.1551 - accuracy: 0.9216 - val_loss: 1.6233 - val_accuracy: 0.9122
train finish
              precision    recall  f1-score   support

           0       0.98      0.97      0.97       980
           1       0.97      0.98      0.98      1135
           2       0.93      0.89      0.91      1032
           3       0.93      0.88      0.90      1010
           4       0.77      0.99      0.87       982
           5       0.83      0.95      0.89       892
           6       0.94      0.95      0.95       958
           7       0.99      0.74      0.85      1028
           8       0.91      0.92      0.92       974
           9       0.92      0.86      0.89      1009

    accuracy                           0.91     10000
   macro avg       0.92      0.91      0.91     10000
weighted avg       0.92      0.91      0.91     10000

[[ 948    0    2    0    9    3   13    0    4    1]
 [   0 1115    3    2    6    1    5    0    3    0]
 [   0    3  919   32   20   17   24    0   17    0]
 [   0    0   19  892    6   69    1    3   16    4]
 [   1    1    1    0  970    1    3    0    1    4]
 [   1    2    2    7    9  849    7    1   13    1]
 [  10    3    3    2   14   10  912    0    3    1]
 [   0   17   31   19  107   32    0  758   10   54]
 [   2    0    5    6   19   23    5    0  900   14]
 [   6    3    3    2   97   14    1    1   18  864]]
done

Process finished with exit code 0

Model: "raw_model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
model_input (InputLayer)     [(None, 71, 71, 3)]       0
_________________________________________________________________
conv1_1 (Conv2D)             (None, 71, 71, 64)        1792
_________________________________________________________________
conv1_2 (Conv2D)             (None, 71, 71, 64)        4160
_________________________________________________________________
mp1 (MaxPooling2D)           (None, 35, 35, 64)        0
_________________________________________________________________
bn1 (BatchNormalization)     (None, 35, 35, 64)        256
_________________________________________________________________
conv2_1 (Conv2D)             (None, 35, 35, 64)        36928
_________________________________________________________________
conv2_2 (Conv2D)             (None, 35, 35, 64)        4160
_________________________________________________________________
mp2 (MaxPooling2D)           (None, 17, 17, 64)        0
_________________________________________________________________
bn2 (BatchNormalization)     (None, 17, 17, 64)        256
_________________________________________________________________
conv3 (Conv2D)               (None, 17, 17, 64)        36928
_________________________________________________________________
conv3_2 (Conv2D)             (None, 17, 17, 64)        4160
_________________________________________________________________
mp3 (MaxPooling2D)           (None, 8, 8, 64)          0
_________________________________________________________________
bn3 (BatchNormalization)     (None, 8, 8, 64)          256
_________________________________________________________________
dense (Dense)                (None, 8, 8, 200)         13000
_________________________________________________________________
gmp (GlobalMaxPooling2D)     (None, 200)               0
_________________________________________________________________
dense_1 (Dense)              (None, 10)                2010
=================================================================
Total params: 103,906
Trainable params: 103,522
Non-trainable params: 384
_________________________________________________________________
None
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
48000/48000 [==============================] - 404s 8ms/sample - loss: 0.3066 - accuracy: 0.9068 - val_loss: 0.1861 - val_accuracy: 0.9419
Epoch 2/10
48000/48000 [==============================] - 421s 9ms/sample - loss: 0.0958 - accuracy: 0.9705 - val_loss: 0.1228 - val_accuracy: 0.9608
Epoch 3/10
48000/48000 [==============================] - 385s 8ms/sample - loss: 0.0719 - accuracy: 0.9770 - val_loss: 0.1138 - val_accuracy: 0.9645
Epoch 4/10
48000/48000 [==============================] - 375s 8ms/sample - loss: 0.0605 - accuracy: 0.9808 - val_loss: 0.1976 - val_accuracy: 0.9492
Epoch 5/10
48000/48000 [==============================] - 367s 8ms/sample - loss: 0.0523 - accuracy: 0.9835 - val_loss: 0.0588 - val_accuracy: 0.9826
Epoch 6/10
48000/48000 [==============================] - 362s 8ms/sample - loss: 0.0433 - accuracy: 0.9862 - val_loss: 0.0877 - val_accuracy: 0.9742
Epoch 7/10
48000/48000 [==============================] - 357s 7ms/sample - loss: 0.0367 - accuracy: 0.9881 - val_loss: 0.1067 - val_accuracy: 0.9718
Epoch 8/10
48000/48000 [==============================] - 354s 7ms/sample - loss: 0.0351 - accuracy: 0.9883 - val_loss: 0.0656 - val_accuracy: 0.9817
Epoch 9/10
48000/48000 [==============================] - 356s 7ms/sample - loss: 0.0294 - accuracy: 0.9904 - val_loss: 0.0504 - val_accuracy: 0.9853
Epoch 10/10
48000/48000 [==============================] - 354s 7ms/sample - loss: 0.0266 - accuracy: 0.9911 - val_loss: 0.1152 - val_accuracy: 0.9695
train finish
              precision    recall  f1-score   support

           0       1.00      0.97      0.98       980
           1       0.84      1.00      0.91      1135
           2       0.98      0.96      0.97      1032
           3       1.00      0.96      0.98      1010
           4       0.99      0.94      0.96       982
           5       0.96      0.97      0.97       892
           6       1.00      0.95      0.97       958
           7       0.97      0.96      0.97      1028
           8       0.99      0.99      0.99       974
           9       0.99      0.96      0.98      1009

    accuracy                           0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000

[[ 950   14    6    0    0    4    3    2    1    0]
 [   0 1135    0    0    0    0    0    0    0    0]
 [   0   39  987    0    0    0    0    5    1    0]
 [   0    7    5  966    0   19    0    9    2    2]
 [   0   57    1    0  920    0    0    3    0    1]
 [   0   14    3    3    0  867    1    2    0    2]
 [   1   29    2    0    4    5  910    0    5    2]
 [   0   37    2    0    0    0    0  989    0    0]
 [   1    4    0    0    1    0    0    0  968    0]
 [   1   16    4    0    7    4    0    5    5  967]]
done